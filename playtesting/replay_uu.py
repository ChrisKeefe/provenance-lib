#!/usr/bin/env python
# -----------------------------------------------------------------------------
# Auto-generated by provenance_py v.0.0.1 at 03:24:33 PM on 01 Mar, 2022

# For User Support, post to the Community Plugin Support channel of the QIIME 2
# Forum: https://forum.qiime2.org
# Documentation/issues: https://github.com/ChrisKeefe/provenance_py.git

# UUIDs of all target QIIME 2 Results are shown at the end of the file

# Instructions for use:
# 1. Open this script in a text editor or IDE. Support for Python
#    syntax highlighting is helpful.
# 2. Search or scan visually for '<' or '>' characters to find places where
#    user input (e.g. a filepath or column name) is required. If syntax
#    highlighting is enabled, input indicators will appear as syntax errors.
# 3. Adjust the arguments to the commands below to suit your data and metadata.
#    If your data is not identical to that in the replayed analysis,
#    changes may be required. (e.g. sample ids or rarefaction depth)
# 4. Activate your replay conda environment, and confirm you have installed all
#    plugins used by the script.
# 5. Run this script with `python <path to this script>`
# -----------------------------------------------------------------------------

from qiime2 import Artifact
from qiime2 import Metadata
import qiime2.plugins.dada2.actions as dada2_actions
import qiime2.plugins.demux.actions as demux_actions
import qiime2.plugins.diversity.actions as diversity_actions
import qiime2.plugins.phylogeny.actions as phylogeny_actions

emp_single_end_sequences_0 = Artifact.import_data(
    'EMPSingleEndSequences',
    <your data here>,
)

# Replay attempts to represent metadata inputs accurately, but metadata .tsv
# files are merged automatically by some interfaces, rendering distinctions
# between file inputs invisible in provenance. We output the recorded metadata
# to disk to enable visual inspection.

# The following command may have received additional metadata .tsv files. To
# confirm you have covered your metadata needs adequately, review the
# originalmetadata, saved at 'recorded_metadata/demux_emp_single_0/'

# NOTE: You may substitute already-loaded Metadata for the following, or cast a
# pandas.DataFrame to Metadata as needed.

barcodes_0_md = Metadata.load(<your metadata filepath>)
barcodes_0_mdc_0 = barcodes_0_md.get_column(<column name>)
per_sample_sequences_0, _ = demux_actions.emp_single(
    seqs=emp_single_end_sequences_0,
    barcodes=barcodes_0_mdc_0,
    rev_comp_barcodes=False,
    rev_comp_mapping_barcodes=False,
)

table_0, representative_sequences_0, _ = dada2_actions.denoise_single(
    demultiplexed_seqs=per_sample_sequences_0,
    trunc_len=120,
    trim_left=0,
    max_ee=2.0,
    trunc_q=2,
    chimera_method='consensus',
    min_fold_parent_over_abundance=1.0,
    n_threads=1,
    n_reads_learn=1000000,
    hashed_feature_ids=True,
)

_, _, _, rooted_tree_0 = phylogeny_actions.align_to_tree_mafft_fasttree(
    sequences=representative_sequences_0,
    n_threads=1,
    mask_max_gap_frequency=1.0,
    mask_min_conservation=0.4,
)

# The following command may have received additional metadata .tsv files. To
# confirm you have covered your metadata needs adequately, review the
# originalmetadata, saved at
# 'recorded_metadata/diversity_core_metrics_phylogenetic_0/'

# NOTE: You may substitute already-loaded Metadata for the following, or cast a
# pandas.DataFrame to Metadata as needed.

metadata_0_md = Metadata.load(<your metadata filepath>)
action_results = diversity_actions.core_metrics_phylogenetic(
    table=table_0,
    phylogeny=rooted_tree_0,
    sampling_depth=1109,
    metadata=metadata_0_md,
    n_jobs=1,
)
unweighted_unifrac_emperor_0_viz = action_results.unweighted_unifrac_emperor


# -----------------------------------------------------------------------------
# The following QIIME 2 Results were parsed to produce this script:
# ffb7cee3-2f1f-4988-90cc-efd5184ef003
# -----------------------------------------------------------------------------
